server:
  port: 8077
  max-http-header-size: 10000000
spring:
  application:
    name: sparkExecutor
  config:
    enableRedis: true
    enableSwagger2: true
  datasource:
    driver-class-name: com.mysql.cj.jdbc.Driver
    url: @db_url@
    username: @db_username@
    password: @db_password@
    hikari:
      pool-name: executeHikariPool
      maximum-pool-size: 12
      connection-timeout: 30000
      minimum-idle: 10
      idle-timeout: 500000
      max-lifetime: 540000
      connection-test-query: SELECT 1
      auto-commit: true
  rabbitmq:
    host: @rabbitmq_host@
    port: 5672
    username: @mq_username@
    password: @mq_password@
  redis:
    host: @redis_host@
    password: @redis_password@
    lettuce:
      pool:
        max-active: 200
        max-wait: 1000
        min-idle: 20
        max-idle: 50
cf: pRaw
spark:
  main:
    class: com.aimsphm.nuclear.task.DownSampleBatchMode
  deployMode: cluster
  default:
    parallelism: 1
  driver:
    memory: 2g
    name: n151
  executor:
    memory: 6g
    cores: 1
    instances: 1
  jar:
    path: /data/sparkJob/spark-job-down-sample-1.0.0.jar
  # 本地测试配置
  home:
    linuxdir: /usr/local/spark-2.4.5-bin-hadoop2.7
  master: spark://10.23.16.205:7077,10.23.16.210:7077
  deploy:
    mode: standalone
initialTimeStampGap: 0
tableName: default:npc_phm_data
eureka:
  client:
    serviceUrl:
      defaultZone: @eureka_master@,@eureka_salver@
    fetchRegistry: true
  instance:
    prefer-ip-address: true
config:
  driver:
    memory:
      hourly: 1g
      daily: 2g
      weekly: 2g
      monthly: 3g
  executor:
    cores:
      hourly: 1
      daily: 2
      weekly: 2
      monthly: 2
    memory:
      hourly: 1g
      daily: 2g
      weekly: 2g
      monthly: 3g
  cron:
    # 每小时的13分
    hourly: 0 13 * * * ?
    # 每天1点23分
    daily: 0 23 1 * * ?
    # 每周一的2点37分钟
    weekly: 0 37 2 ? * MON
    # 每月1号的3点47分
    monthly: 0 47 3 1 * ?

